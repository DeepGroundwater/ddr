{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leakance Impact Figures\n",
    "\n",
    "This notebook generates figures demonstrating the impact of leakance (groundwater-surface water exchange) across CONUS.\n",
    "\n",
    "**Prerequisites:**\n",
    "1. A trained model checkpoint with leakance enabled\n",
    "2. `scripts/router.py` output (`chrout.zarr`) — contains `zeta_sum` and `q_prime_sum`\n",
    "3. Two `scripts/test.py` outputs (`model_test.zarr`) — one with leakance ON, one with leakance OFF (same checkpoint)\n",
    "\n",
    "**Figures:**\n",
    "1. Learned parameter maps (K_D, d_gw, leakance_factor)\n",
    "2. Normalized cumulative zeta map (leakance impact per reach)\n",
    "3. Delta-NSE map (metric improvement from leakance)\n",
    "4. Representative hydrographs (with/without leakance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports + Config\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import xarray as xr\n",
    "import yaml\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from ddr._version import __version__\n",
    "from ddr.io.readers import ForcingsReader\n",
    "from ddr.nn import kan, leakance_lstm\n",
    "from ddr.routing.torch_mc import dmc\n",
    "from ddr.routing.utils import denormalize\n",
    "from ddr.scripts_utils import load_checkpoint\n",
    "from ddr.validation import Config, Metrics, plot_cdf, plot_gauge_map, plot_time_series\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# ── User configuration ──────────────────────────────────────────────\n",
    "CONFIG_PATH = Path(\"./example_config.yaml\")  # Your MERIT leakance config\n",
    "CHROUT_PATH = Path(\"./chrout.zarr\")  # router.py output with zeta_sum\n",
    "TEST_LEAKANCE_ON = Path(\"./model_test_leakance_on.zarr\")  # test.py with leakance\n",
    "TEST_LEAKANCE_OFF = Path(\"./model_test_leakance_off.zarr\")  # test.py without leakance\n",
    "MERIT_SHP = Path(\"./cat_pfaf_7_MERIT_Hydro_v07_Basins_v01_bugfix1.shp\")  # MERIT catchments\n",
    "GAGES_CSV = Path(\"./training_gauges.csv\")  # Gage reference file\n",
    "SAVE_DIR = Path(\"./figures\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = Config(**yaml.safe_load(f))\n",
    "\n",
    "device = torch.device(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Figure 1 — Learned Leakance Parameter Maps (3-panel)\n",
    "#\n",
    "# Run LSTM on forcings + attributes to extract K_D, d_gw, leakance_factor.\n",
    "# Temporal mean gives spatial maps. Join to MERIT shapefile via COMID.\n",
    "\n",
    "# Instantiate KAN (needed for dataset setup) and LSTM\n",
    "nn = kan(\n",
    "    input_var_names=config.kan.input_var_names,\n",
    "    learnable_parameters=config.kan.learnable_parameters,\n",
    "    hidden_size=config.kan.hidden_size,\n",
    "    num_hidden_layers=config.kan.num_hidden_layers,\n",
    "    grid=config.kan.grid,\n",
    "    k=config.kan.k,\n",
    "    seed=config.seed,\n",
    "    device=config.device,\n",
    ")\n",
    "leakance_nn = leakance_lstm(\n",
    "    input_var_names=config.leakance_lstm.input_var_names,\n",
    "    forcing_var_names=config.leakance_lstm.forcing_var_names,\n",
    "    hidden_size=config.leakance_lstm.hidden_size,\n",
    "    num_layers=config.leakance_lstm.num_layers,\n",
    "    dropout=config.leakance_lstm.dropout,\n",
    "    seed=config.seed,\n",
    "    device=config.device,\n",
    ")\n",
    "forcings_reader_nn = ForcingsReader(config)\n",
    "\n",
    "# Load both KAN + LSTM from checkpoint\n",
    "load_checkpoint(nn, config.experiment.checkpoint, device, leakance_nn=leakance_nn)\n",
    "nn = nn.eval()\n",
    "leakance_nn = leakance_nn.eval()\n",
    "\n",
    "# Get dataset\n",
    "dataset = config.geodataset.get_dataset_class(cfg=config)\n",
    "\n",
    "# Batched LSTM leakance inference (avoids GPU OOM on full CONUS ~180k reaches)\n",
    "BATCH_SIZE = 10_000\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_forcings = forcings_reader_nn(\n",
    "        routing_dataclass=dataset.routing_dataclass, device=\"cpu\", dtype=torch.float32\n",
    "    )\n",
    "all_attributes = dataset.routing_dataclass.normalized_spatial_attributes\n",
    "\n",
    "N = all_attributes.shape[0]\n",
    "K_D_cpu = torch.zeros(N, dtype=torch.float16)\n",
    "d_gw_cpu = torch.zeros(N, dtype=torch.float16)\n",
    "lf_cpu = torch.zeros(N, dtype=torch.float16)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start in range(0, N, BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, N)\n",
    "        batch_forcings = all_forcings[:, start:end, :].to(device)\n",
    "        batch_attrs = all_attributes[start:end, :].to(device)\n",
    "\n",
    "        batch_out = leakance_nn(forcings=batch_forcings, attributes=batch_attrs)\n",
    "\n",
    "        K_D_cpu[start:end] = denormalize(\n",
    "            batch_out[\"K_D\"].mean(dim=0), config.params.parameter_ranges[\"K_D\"]\n",
    "        ).cpu().half()\n",
    "        d_gw_cpu[start:end] = denormalize(\n",
    "            batch_out[\"d_gw\"].mean(dim=0), config.params.parameter_ranges[\"d_gw\"]\n",
    "        ).cpu().half()\n",
    "        lf_cpu[start:end] = denormalize(\n",
    "            batch_out[\"leakance_factor\"].mean(dim=0), config.params.parameter_ranges[\"leakance_factor\"]\n",
    "        ).cpu().half()\n",
    "\n",
    "        del batch_forcings, batch_attrs, batch_out\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "del all_forcings\n",
    "\n",
    "K_D = K_D_cpu.float().numpy()\n",
    "d_gw = d_gw_cpu.float().numpy()\n",
    "leakance_factor = lf_cpu.float().numpy()\n",
    "\n",
    "# Join to MERIT shapefile\n",
    "gdf = gpd.read_file(MERIT_SHP).set_index(\"COMID\")\n",
    "divide_ids = np.array(dataset.routing_dataclass.divide_ids)\n",
    "gdf = gdf.loc[divide_ids]\n",
    "gdf[\"K_D\"] = K_D\n",
    "gdf[\"d_gw\"] = d_gw\n",
    "gdf[\"leakance_factor\"] = leakance_factor\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3-panel parameter maps\n",
    "def param_plot(\n",
    "    gdf,\n",
    "    var,\n",
    "    save_name,\n",
    "    cmap=\"plasma\",\n",
    "    unit_label=None,\n",
    "    title=None,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    ascending=False,\n",
    "    dpi=100,\n",
    "):\n",
    "    \"\"\"Create a CONUS parameter map with basemap and colorbar.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7, 4), dpi=dpi)\n",
    "    gdf_clean = gdf.dropna(subset=[var]).sort_values(by=var, ascending=ascending)\n",
    "    data = gdf_clean[var].values\n",
    "    if vmin is None:\n",
    "        vmin = np.min(data)\n",
    "    if vmax is None:\n",
    "        vmax = np.nanmax(data)\n",
    "\n",
    "    gdf_clean.plot(ax=ax, column=var, cmap=cmap, linewidth=0.3, vmin=vmin, vmax=vmax, zorder=1)\n",
    "    cx.add_basemap(\n",
    "        ax, crs=gdf_clean.crs, source=cx.providers.CartoDB.Positron, alpha=0.6, zorder=0, attribution=False\n",
    "    )\n",
    "    ax.set_xlim(-125, -66)\n",
    "    ax.set_ylim(24, 53)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=14)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    sm.set_clim(vmin, vmax)\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(f\"{var} ({unit_label})\" if unit_label else var)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_name, dpi=600, bbox_inches=\"tight\")\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "param_plot(\n",
    "    gdf,\n",
    "    \"K_D\",\n",
    "    SAVE_DIR / \"K_D_map.png\",\n",
    "    cmap=\"viridis\",\n",
    "    title=\"Leakance Coefficient $K_D$ (1/s)\",\n",
    "    unit_label=\"1/s\",\n",
    "    dpi=200,\n",
    ")\n",
    "param_plot(\n",
    "    gdf,\n",
    "    \"d_gw\",\n",
    "    SAVE_DIR / \"d_gw_map.png\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    title=\"Groundwater Depth Threshold $d_{gw}$ (m)\",\n",
    "    unit_label=\"m\",\n",
    "    dpi=200,\n",
    ")\n",
    "param_plot(\n",
    "    gdf,\n",
    "    \"leakance_factor\",\n",
    "    SAVE_DIR / \"leakance_factor_map.png\",\n",
    "    cmap=\"viridis\",\n",
    "    title=\"Leakance Factor\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    dpi=200,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Figure 2 — Normalized Cumulative Zeta Map\n",
    "#\n",
    "# impact = zeta_sum / (q_prime_sum + epsilon)\n",
    "# Positive = losing stream (water lost to groundwater)\n",
    "# Negative = gaining stream (groundwater feeds stream)\n",
    "\n",
    "ds_chrout = xr.open_zarr(CHROUT_PATH)\n",
    "\n",
    "zeta_sum = ds_chrout[\"zeta_sum\"].values\n",
    "q_prime_sum = ds_chrout[\"q_prime_sum\"].values\n",
    "catchment_ids = ds_chrout[\"catchment_ids\"].values\n",
    "\n",
    "epsilon = 1e-6\n",
    "impact = zeta_sum / (q_prime_sum + epsilon)\n",
    "impact = np.clip(impact, -1.0, 1.0)  # Clamp extremes\n",
    "\n",
    "# Join to MERIT shapefile\n",
    "gdf_impact = gpd.read_file(MERIT_SHP).set_index(\"COMID\")\n",
    "gdf_impact = gdf_impact.loc[catchment_ids]\n",
    "gdf_impact[\"leakance_impact\"] = impact\n",
    "gdf_impact = gdf_impact.to_crs(epsg=4326)\n",
    "\n",
    "param_plot(\n",
    "    gdf_impact,\n",
    "    \"leakance_impact\",\n",
    "    SAVE_DIR / \"leakance_impact_map.png\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    title=\"Normalized Cumulative Leakance ($\\\\sum \\\\zeta / \\\\sum q'$)\",\n",
    "    vmin=-0.5,\n",
    "    vmax=0.5,\n",
    "    dpi=200,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Figure 3 — Delta-NSE Map (Leakance ON minus OFF)\n",
    "#\n",
    "# Compare two test.py runs (same checkpoint, leakance toggled at inference)\n",
    "\n",
    "ds_on = xr.open_zarr(TEST_LEAKANCE_ON)\n",
    "ds_off = xr.open_zarr(TEST_LEAKANCE_OFF)\n",
    "\n",
    "# Align on common gages\n",
    "common_gages = np.intersect1d(ds_on.gage_ids.values, ds_off.gage_ids.values)\n",
    "ds_on = ds_on.sel(gage_ids=common_gages)\n",
    "ds_off = ds_off.sel(gage_ids=common_gages)\n",
    "\n",
    "metrics_on = Metrics(pred=ds_on.predictions.values, target=ds_on.observations.values)\n",
    "metrics_off = Metrics(pred=ds_off.predictions.values, target=ds_off.observations.values)\n",
    "\n",
    "nse_on = np.clip(metrics_on.nse, -1, 1)\n",
    "nse_off = np.clip(metrics_off.nse, -1, 1)\n",
    "delta_nse = nse_on - nse_off\n",
    "\n",
    "# Build gage DataFrame for plotting\n",
    "gages_df = pd.read_csv(GAGES_CSV)\n",
    "gages_df[\"STAID\"] = gages_df[\"STAID\"].astype(str).str.zfill(8)\n",
    "gages_df = gages_df.set_index(\"STAID\")\n",
    "selected_gages = gages_df.loc[common_gages].reset_index()\n",
    "selected_gages[\"delta_NSE\"] = delta_nse\n",
    "selected_gages[\"NSE_leakance_on\"] = nse_on\n",
    "selected_gages[\"NSE_leakance_off\"] = nse_off\n",
    "\n",
    "# Map\n",
    "fig = plot_gauge_map(\n",
    "    gages=selected_gages,\n",
    "    metric_column=\"delta_NSE\",\n",
    "    title=r\"$\\Delta$NSE (Leakance ON $-$ OFF)\",\n",
    "    colormap=\"RdBu\",\n",
    "    colorbar_label=r\"$\\Delta$NSE\",\n",
    "    vmin=-0.1,\n",
    "    vmax=0.1,\n",
    "    figsize=(16, 8),\n",
    "    point_size=30,\n",
    "    path=SAVE_DIR / \"delta_nse_map.png\",\n",
    "    show_plot=True,\n",
    ")\n",
    "\n",
    "# CDF overlay\n",
    "fig_cdf, ax_cdf = plot_cdf(\n",
    "    data_list=[nse_off, nse_on],\n",
    "    title=\"NSE CDF: Leakance ON vs OFF\",\n",
    "    legend_labels=[\"Leakance OFF\", \"Leakance ON\"],\n",
    "    figsize=(10, 6),\n",
    "    xlabel=\"NSE\",\n",
    "    ylabel=\"Cumulative Frequency\",\n",
    "    reference_line=None,\n",
    "    xlim=(0, 1),\n",
    ")\n",
    "plt.savefig(SAVE_DIR / \"nse_cdf_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Median NSE (leakance ON):  {np.nanmedian(nse_on):.4f}\")\n",
    "print(f\"Median NSE (leakance OFF): {np.nanmedian(nse_off):.4f}\")\n",
    "print(f\"Median delta-NSE:          {np.nanmedian(delta_nse):.4f}\")\n",
    "print(f\"Gages improved:            {np.sum(delta_nse > 0)} / {len(delta_nse)}\")\n",
    "print(f\"Gages degraded:            {np.sum(delta_nse < 0)} / {len(delta_nse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Figure 4 — Representative Hydrographs\n",
    "#\n",
    "# Select gages by delta-NSE ranking: best improved, worst degraded, neutral.\n",
    "\n",
    "# Rank gages by delta-NSE\n",
    "ranked = selected_gages.sort_values(\"delta_NSE\", ascending=False)\n",
    "best_improved = ranked.iloc[0]\n",
    "worst_degraded = ranked.iloc[-1]\n",
    "neutral_idx = (ranked[\"delta_NSE\"].abs()).idxmin()\n",
    "neutral = ranked.loc[neutral_idx]\n",
    "\n",
    "representative_gages = [best_improved, neutral, worst_degraded]\n",
    "panel_labels = [\"Best Improved\", \"Neutral\", \"Most Degraded\"]\n",
    "\n",
    "time_range = ds_on.time.values\n",
    "\n",
    "for gage_info, label in zip(representative_gages, panel_labels, strict=False):\n",
    "    gage_id = gage_info[\"STAID\"]\n",
    "    gage_name = gage_info.get(\"STANAME\", gage_id)\n",
    "\n",
    "    pred_on = ds_on.sel(gage_ids=gage_id).predictions.values\n",
    "    pred_off = ds_off.sel(gage_ids=gage_id).predictions.values\n",
    "    obs = ds_on.sel(gage_ids=gage_id).observations.values\n",
    "\n",
    "    gage_metrics_on = {\"nse\": float(gage_info[\"NSE_leakance_on\"])}\n",
    "    gage_metrics_off = {\"nse\": float(gage_info[\"NSE_leakance_off\"])}\n",
    "\n",
    "    title = f\"{label}: {gage_name} ({gage_id}) | $\\\\Delta$NSE={gage_info['delta_NSE']:.4f}\"\n",
    "\n",
    "    plot_time_series(\n",
    "        prediction=pred_on,\n",
    "        observation=obs,\n",
    "        time_range=time_range,\n",
    "        gage_id=gage_id,\n",
    "        name=gage_name,\n",
    "        metrics=gage_metrics_on,\n",
    "        path=SAVE_DIR / f\"hydrograph_{gage_id}_{label.lower().replace(' ', '_')}.png\",\n",
    "        title=title,\n",
    "        additional_predictions=[\n",
    "            (pred_off, \"DDR (no leakance)\", gage_metrics_off),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "print(\"Hydrograph figures saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
