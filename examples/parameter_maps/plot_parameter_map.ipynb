{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "##### Creating a parameter map\n",
    "\n",
    "This notebook is meant to show the user how to create a parameter map to see what the spatial distribution of learned parameters looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run imports\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from ddr._version import __version__\n",
    "from ddr.geodatazoo.lynker_hydrofabric import LynkerHydrofabric\n",
    "from ddr.io.readers import ForcingsReader, StreamflowReader as streamflow\n",
    "from ddr.nn import kan, leakance_lstm\n",
    "from ddr.routing.torch_mc import dmc\n",
    "from ddr.routing.utils import denormalize\n",
    "from ddr.scripts_utils import load_checkpoint\n",
    "from ddr.validation import Config\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a config\n",
    "with open(\"./example_config.yaml\") as f:\n",
    "    config = Config(**yaml.safe_load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate objects required for routing\n",
    "device = torch.device(f\"cuda:{config.device}\")\n",
    "nn = kan(\n",
    "    input_var_names=config.kan.input_var_names,\n",
    "    learnable_parameters=config.kan.learnable_parameters,\n",
    "    hidden_size=config.kan.hidden_size,\n",
    "    num_hidden_layers=config.kan.num_hidden_layers,\n",
    "    grid=config.kan.grid,\n",
    "    k=config.kan.k,\n",
    "    seed=config.seed,\n",
    "    device=config.device,\n",
    ")\n",
    "routing_model = dmc(cfg=config, device=device)\n",
    "flow = streamflow(config)\n",
    "dataset = config.geodataset.get_dataset_class(cfg=config)\n",
    "\n",
    "# Instantiate LSTM + ForcingsReader for leakance parameters\n",
    "leakance_nn = None\n",
    "forcings_reader = None\n",
    "if config.params.use_leakance:\n",
    "    leakance_nn = leakance_lstm(\n",
    "        input_var_names=config.leakance_lstm.input_var_names,\n",
    "        forcing_var_names=config.leakance_lstm.forcing_var_names,\n",
    "        hidden_size=config.leakance_lstm.hidden_size,\n",
    "        num_layers=config.leakance_lstm.num_layers,\n",
    "        dropout=config.leakance_lstm.dropout,\n",
    "        seed=config.seed,\n",
    "        device=config.device,\n",
    "    )\n",
    "    forcings_reader = ForcingsReader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model states (KAN + optional LSTM)\n",
    "model_states = Path(config.experiment.checkpoint)\n",
    "load_checkpoint(nn, model_states, device, leakance_nn=leakance_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate KAN parameters (hydraulic only: n, q_spatial, top_width, side_slope)\n",
    "nn = nn.eval()\n",
    "with torch.no_grad():\n",
    "    spatial_params = nn(inputs=dataset.routing_dataclass.normalized_spatial_attributes.to(device))\n",
    "\n",
    "spatial_params[\"n\"] = denormalize(spatial_params[\"n\"], config.params.parameter_ranges[\"n\"])\n",
    "# spatial_params[\"side_slope\"] = denormalize(spatial_params[\"side_slope\"], config.params.parameter_ranges[\"side_slope\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LSTM leakance parameters (temporal mean for spatial maps)\n",
    "if leakance_nn is not None and forcings_reader is not None:\n",
    "    leakance_nn = leakance_nn.eval()\n",
    "    with torch.no_grad():\n",
    "        forcing_data = forcings_reader(\n",
    "            routing_dataclass=dataset.routing_dataclass, device=device, dtype=torch.float32\n",
    "        )\n",
    "        leakance_params = leakance_nn(\n",
    "            forcings=forcing_data,\n",
    "            attributes=dataset.routing_dataclass.normalized_spatial_attributes.to(device),\n",
    "        )\n",
    "    # Temporal mean for spatial maps — shape (T, N) → (N,)\n",
    "    spatial_params[\"K_D\"] = denormalize(\n",
    "        leakance_params[\"K_D\"].mean(dim=0), config.params.parameter_ranges[\"K_D\"]\n",
    "    )\n",
    "    spatial_params[\"d_gw\"] = denormalize(\n",
    "        leakance_params[\"d_gw\"].mean(dim=0), config.params.parameter_ranges[\"d_gw\"]\n",
    "    )\n",
    "    spatial_params[\"leakance_factor\"] = denormalize(\n",
    "        leakance_params[\"leakance_factor\"].mean(dim=0), config.params.parameter_ranges[\"leakance_factor\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map parameters back to the hydrofabric\n",
    "if config.geodataset == \"lynker_hydrofabric\":\n",
    "    gdf = gpd.read_file(config.data_sources.geospatial_fabric_gpkg, layer=\"divides\").set_index(\"divide_id\")\n",
    "    divide_ids = np.array([f\"cat-{_id}\" for _id in dataset.hf_ids])\n",
    "    gdf = gdf.reindex(divide_ids)\n",
    "    gdf[\"n\"] = spatial_params[\"n\"].cpu().numpy()\n",
    "    gdf[\"q_spatial\"] = spatial_params[\"q_spatial\"].cpu().numpy()\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "elif config.geodataset == \"merit\":\n",
    "    gdf = gpd.read_file(config.data_sources.geospatial_fabric_gpkg).set_index(\"COMID\")\n",
    "    divide_ids = np.array(dataset.routing_dataclass.divide_ids)\n",
    "    gdf = gdf.loc[divide_ids]\n",
    "    gdf[\"n\"] = spatial_params[\"n\"].cpu().numpy()\n",
    "    gdf[\"q_spatial\"] = spatial_params[\"q_spatial\"].cpu().numpy()\n",
    "    gdf[\"side_slope\"] = spatial_params[\"side_slope\"].cpu().numpy()\n",
    "    if config.params.use_leakance:\n",
    "        gdf[\"K_D\"] = spatial_params[\"K_D\"].cpu().numpy()\n",
    "        gdf[\"d_gw\"] = spatial_params[\"d_gw\"].cpu().numpy()\n",
    "        gdf[\"leakance_factor\"] = spatial_params[\"leakance_factor\"].cpu().numpy()\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_plot(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    var: str,\n",
    "    save_name: Path,\n",
    "    cmap: str = \"plasma\",\n",
    "    unit_label: str | None = None,\n",
    "    title: str | None = None,\n",
    "    vmin: float | None = None,\n",
    "    vmax: float | None = None,\n",
    "    ascending: bool = False,\n",
    "    dpi: int = 100,\n",
    ") -> tuple[Figure, Axes]:\n",
    "    \"\"\"\n",
    "    Create a parameter plot for geospatial data with a basemap and colorbar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : gpd.GeoDataFrame\n",
    "        GeoDataFrame containing the data to plot.\n",
    "    var : str\n",
    "        Column name to visualize.\n",
    "    save_name : str\n",
    "        Filename for saving the plot.\n",
    "    cmap : str, default 'plasma'\n",
    "        Colormap name for the plot.\n",
    "    unit_label : str, optional\n",
    "        Unit label for the colorbar.\n",
    "    title : str, optional\n",
    "        Title for the plot.\n",
    "    vmin : float, optional\n",
    "        Minimum value for color scaling. If None, uses data minimum.\n",
    "    vmax : float, optional\n",
    "        Maximum value for color scaling. If None, uses data maximum.\n",
    "    ascending : bool, default False\n",
    "        Whether to sort data in ascending order.\n",
    "    dpi : int, default 100\n",
    "        DPI for the figure display.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (matplotlib.figure.Figure, matplotlib.axes.Axes)\n",
    "        Figure and axes objects for further customization.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "        If the specified variable column doesn't exist in the GeoDataFrame.\n",
    "    ValueError\n",
    "        If the GeoDataFrame is empty after dropping NaN values.\n",
    "\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if var not in gdf.columns:\n",
    "        raise KeyError(f\"Column '{var}' not found in GeoDataFrame\")\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(7, 4), dpi=dpi)\n",
    "\n",
    "    # Drop NaNs and validate data\n",
    "    gdf_clean = gdf.dropna(subset=[var])\n",
    "    if gdf_clean.empty:\n",
    "        raise ValueError(f\"No valid data found for variable '{var}' after dropping NaN values\")\n",
    "\n",
    "    # Sort data for visualization\n",
    "    gdf_clean = gdf_clean.sort_values(by=var, ascending=ascending)\n",
    "    data = gdf_clean[var].values\n",
    "\n",
    "    # Set vmin and vmax if not provided\n",
    "    if vmin is None:\n",
    "        vmin = np.min(data)\n",
    "    if vmax is None:\n",
    "        vmax = np.nanmax(data)\n",
    "\n",
    "    # Create the plot with direct vmin/vmax limits\n",
    "    gdf_clean.plot(\n",
    "        ax=ax,\n",
    "        column=var,\n",
    "        cmap=cmap,\n",
    "        linewidth=0.3,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        zorder=1,\n",
    "    )\n",
    "\n",
    "    # Add basemap\n",
    "    cx.add_basemap(\n",
    "        ax,\n",
    "        crs=gdf_clean.crs,\n",
    "        source=cx.providers.CartoDB.Positron,\n",
    "        alpha=0.6,\n",
    "        zorder=0,\n",
    "        attribution=False,\n",
    "    )\n",
    "\n",
    "    # Set bounds for CONUS\n",
    "    ax.set_xlim(-125, -66)\n",
    "    ax.set_ylim(24, 53)\n",
    "\n",
    "    # Remove axis ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Set plot title\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=14)\n",
    "\n",
    "    # Add colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    sm.set_clim(vmin, vmax)\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "\n",
    "    # Set colorbar label\n",
    "    label_text = var\n",
    "    if unit_label:\n",
    "        label_text = f\"{var} ({unit_label})\"\n",
    "    cbar.set_label(label_text)\n",
    "\n",
    "    # Format tick values to show appropriate precision\n",
    "    cbar.formatter.set_powerlimits((-2, 2))\n",
    "    cbar.update_ticks()\n",
    "\n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    # Note: config.params.save_path reference removed - you'll need to pass the full path\n",
    "    # or import your config module\n",
    "    plt.savefig(save_name, dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "param_plot(\n",
    "    gdf,\n",
    "    \"n\",\n",
    "    Path(config.params.save_path) / \"n_train.png\",\n",
    "    vmax=0.2,\n",
    "    cmap=\"plasma_r\",\n",
    "    title=\"Manning's Roughness (m⁻¹/³s)\",\n",
    "    ascending=True,\n",
    "    dpi=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_plot(\n",
    "#     gdf,\n",
    "#     \"side_slope\",\n",
    "#     Path(config.params.save_path) / \"side_slope_train.png\",\n",
    "#     cmap=\"plasma_r\",\n",
    "#     title=\"side_slope\",\n",
    "#     ascending=True,\n",
    "#     dpi=200,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.loc[divide_ids]\n",
    "gdf[\"n\"] = spatial_params[\"n\"].cpu().numpy()\n",
    "plt.scatter(np.log(gdf[\"uparea\"]), gdf[\"n\"], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
